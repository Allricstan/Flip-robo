{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a01d3f",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1cb09b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing requried libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5bc74afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Arvind\\chromedriver.exe\") ### installing Chrome driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff7ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Storing url and getting data from url.\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b0cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_jobs = driver.find_element_by_id('qsb-keyword-sugg')### Storing search bar element\n",
    "search_jobs.send_keys('Data Analyst') ### Sending keys to search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78385fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_xpath('//input[@id=\"qsb-location-sugg\"]') ### storing location element.\n",
    "location.send_keys('Bangalore') ### Sending keys to location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10a2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('//button[@class=\"btn\"]') ### Storing search button.\n",
    "search.click() ### Clicking on search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077e8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]') #### Scraping Job titles from page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d04982",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[] #### Storing job titles in List.\n",
    "for x in Titles_tag:\n",
    "    job_titles.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b5a632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Specialist - Data Analyst',\n",
       " 'Business/Data Analyst - SSE/LA',\n",
       " 'Business Data Analyst II',\n",
       " 'Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst/Business Analyst-Gurgaon/Bangalore/Mumbai (only Females)',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data/Business Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst - SQL/Tableau/Redshift',\n",
       " 'Marketing Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b263800",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]') #### Scraping companies name from page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7aaab00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philips India Limited',\n",
       " 'CGI Information Systems and Management Consultants',\n",
       " 'Infobahn Softworld Inc.',\n",
       " 'WEIWO Communication Pvt. Ltd.',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software',\n",
       " 'India Medtronic Pvt. Ltd,.',\n",
       " 'SMEDC SERVICES PRIVATE LIMITED',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Enzen Global Solutions Pvt. Ltd',\n",
       " 'CGI Information Systems and Management Consultants',\n",
       " 'Liventus, Inc.',\n",
       " 'Pronto Consulting Services',\n",
       " 'Qlik',\n",
       " 'Gojek Tech',\n",
       " 'GO-JEK India',\n",
       " 'Eli Lilly Services India Private Limited',\n",
       " 'Infobahn Softworld Inc.',\n",
       " 'GCC SERVICES INDIA PRIVATE LIMITED']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_name = [] ### Storing companies name in list.\n",
    "for x in companies_tag:\n",
    "    companies_name.append(x.text)\n",
    "companies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21411a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "expirence_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span') ### Scraping exprience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa5a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-8 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-8 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '1-4 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '5-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '2-7 Yrs',\n",
       " '1-4 Yrs',\n",
       " '3-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-9 Yrs',\n",
       " '5-9 Yrs']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Expirence_required = [] ### Storing expirence data in list \n",
    "for i in expirence_tag:\n",
    "    Expirence_required.append(i.text)\n",
    "Expirence_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8511ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span[1]') ### Scraping location data from website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2447501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Ulsoor)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(2nd Phase JP Nagar)',\n",
       " 'Noida, Mumbai, Indore, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_location = [] ### Storing location data in list.\n",
    "for i in location_tag:\n",
    "    Job_location.append(i.text)\n",
    "Job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd63f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "### Checking length of all the tags\n",
    "print(len(job_titles),len(Job_location),len(Expirence_required),len(companies_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc28b8b",
   "metadata": {},
   "source": [
    "### Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aea6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_jobs = pd.DataFrame({})\n",
    "first_10_jobs['Job Titles'] = job_titles[:10]\n",
    "first_10_jobs['job-location'] = Job_location[:10]\n",
    "first_10_jobs['company_name'] = companies_name[:10]\n",
    "first_10_jobs['experience_required'] = Expirence_required[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf6015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Specialist - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business/Data Analyst - SSE/LA</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CGI Information Systems and Management Consult...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infobahn Softworld Inc.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst/Business Analyst-Gurgaon/Bangalor...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>India Medtronic Pvt. Ltd,.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SMEDC SERVICES PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0                   Senior Specialist - Data Analyst   \n",
       "1                     Business/Data Analyst - SSE/LA   \n",
       "2                           Business Data Analyst II   \n",
       "3                                       Data Analyst   \n",
       "4                              Business Data Analyst   \n",
       "5                              Business Data Analyst   \n",
       "6  Data Analyst/Business Analyst-Gurgaon/Bangalor...   \n",
       "7                                Senior Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                        Bangalore/Bengaluru(Ulsoor)   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        company_name experience_required  \n",
       "0                              Philips India Limited             4-8 Yrs  \n",
       "1  CGI Information Systems and Management Consult...             2-5 Yrs  \n",
       "2                            Infobahn Softworld Inc.             5-8 Yrs  \n",
       "3                      WEIWO Communication Pvt. Ltd.             4-8 Yrs  \n",
       "4                                   Trigent Software             3-5 Yrs  \n",
       "5                                   Trigent Software             3-5 Yrs  \n",
       "6                         India Medtronic Pvt. Ltd,.             1-4 Yrs  \n",
       "7                     SMEDC SERVICES PRIVATE LIMITED             5-8 Yrs  \n",
       "8                   Allegis Services India Pvt. Ltd.             2-5 Yrs  \n",
       "9                   Allegis Services India Pvt. Ltd.             3-5 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5ea6b",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a41f5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Arvind\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c241ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fb88952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2b1be214",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_search = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input')\n",
    "location_search.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a4e001fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_class_name('btn')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "de6cc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist: Advanced Analytics',\n",
       " 'Senior Data & Applied Scientist',\n",
       " 'Data & Applied Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'DATA SCIENTIST',\n",
       " 'Senior Data Scientist',\n",
       " 'Python - Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Western Digital Data Scientist 3',\n",
       " 'Western Digital Data Scientist',\n",
       " 'Data Scientist 4',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist - Permanent Role',\n",
       " 'Data Scientist 4',\n",
       " 'Data Scientist',\n",
       " 'Immediate Openings For DATA Scientist with 6 To 7 yrs of Experience',\n",
       " 'Software Developer - Data Scientist / NLP / Machine Learning & Dot Net',\n",
       " 'Hiring Data Scientist',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs = [] \n",
    "for x in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "    Jobs.append(x.text)\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "25c54fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(5th block Koramangala)',\n",
       " 'New Delhi, Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location = []\n",
    "for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span[1]'):\n",
    "    Location.append(i.text)\n",
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "906b01cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " 'Microsoft Corporation',\n",
       " 'Microsoft Corporation',\n",
       " 'Philips India Limited',\n",
       " 'McAfee Software (India) Pvt. Ltd',\n",
       " 'SYMBIOSIS International W.L.L',\n",
       " 'Mindtree Limited',\n",
       " 'Datamatics Global Services Ltd',\n",
       " 'Publicis Groupe',\n",
       " 'Western Digital',\n",
       " 'Western Digital',\n",
       " 'Western Digital',\n",
       " 'Bidgely Technologies Private Limited',\n",
       " 'Onward Technologies Limited',\n",
       " 'Western Digital',\n",
       " 'HotelHub',\n",
       " 'Entune IT Consulting Private Limited',\n",
       " 'Cunesoft India Private Limited',\n",
       " 'IHX private limited',\n",
       " 'Goals 101 Data Solutions Pvt. Ltd.']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = []\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "    companies.append(i.text)\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4f505047",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_opening_urls = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4627e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bangalore-bengaluru-5-to-10-years-060821907733?src=jobsearchDesk&sid=16284124969456899&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-applied-scientist-microsoft-india-r-and-d-pvt-ltd-bangalore-bengaluru-3-to-5-years-060821501871?src=jobsearchDesk&sid=16284124969456899&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-applied-scientist-microsoft-india-r-and-d-pvt-ltd-bangalore-bengaluru-3-to-7-years-060821501870?src=jobsearchDesk&sid=16284124969456899&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-philips-india-limited-bangalore-bengaluru-8-to-10-years-060821501599?src=jobsearchDesk&sid=16284124969456899&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-mcafee-software-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-050821501145?src=jobsearchDesk&sid=16284124969456899&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-symbiosis-international-w-l-l-bangalore-bengaluru-10-to-15-years-050821004331?src=jobsearchDesk&sid=16284124969456899&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-python-data-scientist-mindtree-limited-bangalore-bengaluru-3-to-5-years-040821500207?src=jobsearchDesk&sid=16284124969456899&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-datamatics-global-services-ltd-bangalore-bengaluru-8-to-13-years-040821003517?src=jobsearchDesk&sid=16284124969456899&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-publicis-groupe-bangalore-bengaluru-2-to-5-years-030821501259?src=jobsearchDesk&sid=16284124969456899&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-western-digital-data-scientist-3-western-digital-bangalore-bengaluru-4-to-5-years-030821500726?src=jobsearchDesk&sid=16284124969456899&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-western-digital-data-scientist-western-digital-bangalore-bengaluru-10-to-12-years-030821500725?src=jobsearchDesk&sid=16284124969456899&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-4-western-digital-bangalore-bengaluru-6-to-8-years-030821500721?src=jobsearchDesk&sid=16284124969456899&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-bidgely-technologies-private-limited-bangalore-bengaluru-4-to-6-years-030821500043?src=jobsearchDesk&sid=16284124969456899&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-permanent-role-onward-technologies-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-11-years-030821002780?src=jobsearchDesk&sid=16284124969456899&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-4-western-digital-bangalore-bengaluru-5-to-6-years-020821500513?src=jobsearchDesk&sid=16284124969456899&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-hotelhub-bangalore-bengaluru-6-to-11-years-020821500146?src=jobsearchDesk&sid=16284124969456899&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-immediate-openings-for-data-scientist-with-6-to-7-yrs-of-experience-entune-it-consulting-private-limited-kolkata-hyderabad-secunderabad-pune-ahmedabad-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-5-to-8-years-020821005914?src=jobsearchDesk&sid=16284124969456899&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-software-developer-data-scientist-nlp-machine-learning-dot-net-cunesoft-india-private-limited-bangalore-bengaluru-3-to-8-years-190121001281?src=jobsearchDesk&sid=16284124969456899&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-data-scientist-ihx-private-limited-bangalore-bengaluru-4-to-6-years-090721002695?src=jobsearchDesk&sid=16284124969456899&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-goals-101-data-solutions-pvt-ltd-new-delhi-bangalore-bengaluru-delhi-ncr-4-to-8-years-030821000870?src=jobsearchDesk&sid=16284124969456899&xp=20&px=1']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_decrip = []\n",
    "for i in job_opening_urls:\n",
    "    job_decrip.append(i.get_attribute('href'))\n",
    "job_decrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9b269e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Job description\\n  Be a part of the Enterprise IT , Information and Data Science team and drive a strategic and actionable Data Science architecture to activate the needed business capabilities. Deliver business use cases like Care Provider (Customer, Product , IB ) 360 initiative, Product bundling , Value Based pricing , Conversational AI, Indirect Trade partner classification , Data pipeline predictions etc - an ambition to better understand the needs of Healthcare Providers, the way Philips serves its customers and how and where Philips can add value to the customer decision journey.\\nYour responsibilities\\nEnsure strategic direction for data science capabilities for Philips is created and kept up to date on a regular basis\\nContinuously evaluate the latest techniques in Artificial intelligence, machine learning, robotics, statistical analysis\\nImplement advanced algorithms for business problems based on statistical analysis, coding, deep learning, advanced data mining techniques etc.\\nDevelop new algorithms if necessary, to bring predictive, advanced statistics / learning based solutions\\nDevelop algorithms to further automate processes and feed insights back into PIL for better business outcome\\nCo-create with business / market / functions or IT platforms on requirements\\nEnsure quality of data and solution developed\\nLead and drive data mining, creating algorithms, collection of data, collection of procedures during the design, build phases of a project\\nLead and drive in deploy and testing of the solutions and insights\\nSpot and evaluate emerging/cutting edge, open source, data science/machine learning libraries\\nYou are part of:\\nYou will be part of Group IT , Information and Data Management team that drives business impact through Data Science and Advanced analytics. A team that instigates collaboration across diverse teams globally to manage Data as an asset at Philips.\\nCore competencies needed to be successful:\\nA Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent;\\n8-10 years of overall experience in data science, data analytics roles\\n8+ years of experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas\\nExperience in driving implementation of solutions, data and algorithms on data warehouse and lakes like Azure , AWS, SQL etc\\nDemonstrable advanced programming experience in Python or another programming language such as Azure ML/R/Python etc ;\\nStrong analytical and social skills and the capability to translate data intelligence into valuable insights for the senior stakeholders in the company\\nAbility to formulate multiple complex business problems into hypothesis and proof of concepts for testing\\nManage Projects and lead a sub-portfolio of data science project teams to deliver results\\nCoach, Guide and direct teams of internal and vendor resources\\nCollaborate across IT platform teams to deploy solutions and drive continuous improvements\\nManage senior stakeholder in the company in a matrix organization i.e. Market / BG / Function leaders\\nRoleBusiness/EDP Analyst\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaITES, BPO, KPO, LPO, Customer Service, Operations\\nEmployment TypeFull Time, Permanent\\nRole CategoryOperations\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nComputer scienceData managementCodingAnalyticalMachine learningHealthcareData miningRoboticsSQLPython', '----', \"Job description\\nRequired Candidate profile\\nWe are looking for a Senior Data Scientist with a min of 10 years experience in Banking Financial Domain (especially Compliance related) and a solid background in Cloudera.\\nAs a Cloudera Specialist, you must be adept in Cloudera tools like CDH, CEPH, CM, CMA, Data node EDH, HVE, JAS, NameNode, Nodemanager, QJM, QJN, RM and ZK.\\nThis will be a two years assignment to one of the Leading Class A banks in Abu Dhabi.\\nCandidate should have finished two or three full implementations of Data Analytics in Compliance in large Enterprise Banks.\\nShould be having thorough knowledge in R, Python, Scala on demand and Jupyter Notebooks.\\nShould be having hands experience in CCA Spark and Hadoop developer.\\nShould be having a Financial Compliance Background with a good knowledge and hands on expertise on Compliance related domains.\\nShould be a Machine Learning expert and create new models and use various library in that area. You should have proven skills in this area.\\nShould be having a thorough theoretical and practical idea on the following systems (From a Data Scientist Perspective)\\nHDFS\\nYarn\\nMapReduce\\nHive\\nPig\\nApache Ambari\\nHBase / Apache Impala\\nStorm\\nOozie\\nRanger\\nZookeeper\\nVarious data ingestion tools like Sqoop, flume, Kafka\\nVarious reporting tools like Drill, Phoenix, Zeppelin\\nWill be an added advantage if you have exposure to GPU processing, Tensor Flow and Data Lakes.\\nShould be able to produce high Quality Business documentation, Project Management, Agile Framework practices as needed.\\nShould inspect the current Cloudera Architecture and suggest enhancements or improve it.\\nShould be able to communicate with Senior Business Management ideas, concepts and deliverables.\\nIf you have certifications on Cloudera (Cloudera Data Engineer, Spark and Hadoop Developer), it will be an added advantage.\\nData Scientist - Compliance\\nResponsibilities:\\nUse advanced analytics methods to extract value from business data\\nPerform large-scale experimentation and build data-driven models to answer business questions\\nConduct research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence\\nDetermine requirements that will be used to train and evolve deep learning models and algorithms\\nArticulate a vision and roadmap for the exploitation of data as a valued corporate asset\\nInfluence product teams through presentation of data-based recommendations\\nEvangelize best practices to analytics and products teams\\nAssemble large, complex data sets that meet functional / non-functional business requirements.\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing analytics delivery, re-designing infrastructure for greater scalability, etc.\\nBuild analytics tools that utilize the data to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with analytics related technical issues and support their data infrastructure needs.\\nWork with data and analytics experts to strive for greater functionality data systems\\nTypical skills and background:\\nSKILLS:\\nCan work with data to identify patterns.\\nUse judgement to form conclusions that may challenge conventional wisdom and focus on the crux of issues to identify high-leverage intervention points and strategies.\\nRapidly acquire new knowledge and learn new skills\\nSeek to understand business needs and get results that have a clear, positive, and direct impact on business performance\\nApply different strategies to convince others to change their opinions or plans and ensure that proposals or arguments are supported by strong logic and a compelling business case, addressing all relevant factors.\\nConsider the relative costs and benefits of potential actions to choose the most appropriate one\\nCommunication and storytelling\\nTeamwork and collaboration\\nBanking domain business knowledge\\nAdvanced analytics modelling and orchestration\\nSolid development skills in Java, Scala and SQL\\nSound knowledge of using data science tools and languages like Cloudera Data Science Workbench (CDSW), Jupyter Notebook, Python etc.\\nClear hands-on mastery in big datab systems - Hadoop ecosystem, Cloud technologies (AWS, Azure, Google), in-memory database systems (HANA, Hazel cast, etc) and other database systems - traditional RDBMS (Terradata, SQL Server, Oracle), and NoSQL databases (Cassandra, MongoDB, DynamoDB)\\nComfortable in dashboard development (Tableau, Powerbi, Qlik, etc) and in developing data analytics models (R, Python, Spark)\\nEXPERIENCE AND QUALIFICATION:\\nMasters degree from top-tier college/university in Computer Science, Statistics, Economics, or other closely-related field\\nMinimum of 6 years' hands-on experience with a strong data background\\nExtensive experience working with Big Data tools and building data solutions for advanced analytics\\nExperience with statistical software, scripting languages, and packages (e.g. R, MATLAB, SAS, and Python)\\nConsiderable experience in solving business problems with advanced analytical solutions\\nProven experience in conducting statistical analysis and building models with advanced scripting language such as R, SPSS, or other analytic tools.\\nExperience building and deploying predictive models, web scraping, and scalable data pipelines.\\nStrong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modeling\\nPractical knowledge across data extraction and transformation tools - traditional ETL tools (Informatica, Altryx) as well as more recent big data tools\\nFinancial Renumeration will be based on your skills and expertise.\\nNotice Period of 30 to 45 days preferred\\nPrevious working experience in Middle East and Gulf regions preferred Roles and Responsibilities\\n\\n\\nDesired Candidate Profile\\n\\n\\nPerks and Benefits\\n\\n\\nRoleData Analyst\\nIndustry TypeBanking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nKey Skills\\nData ScienceBig Data AnalyticsHiveSqoopHdfs\", 'Job description\\nData Scientist Primary Location India, Bangalore Date posted 08/01/2021\\nApply Now Save Job ID: JR0024575\\n\\n\\nJob Title:\\nData Scientist\\n\\n\\nRole Overview:\\nData scientist will be doing research on innovative projects in platform engineering group at McAfee. Platform Engineering Group is the is one of the core groups responsible for collecting data from millions of sensors from various products of Enterprises, using the data to protect the customers, provide insights and necessary actions to be taken for security gap.\\n\\nThis position is an integral part of the McAfee Enterprise business segment which was acquired by Symphony Technology Group (STG) in July 2021. McAfee Enterprise and its team members remain committed to keeping governments and enterprises safe. This position is dedicated to and part of the McAfee Enterprise business.\\n\\n\\n\\nCompany Overview\\nMcAfee is a leader in personal security for consumers. Focused on protecting people, not just devices, McAfee consumer solutions adapt to users needs in an always online world, empowering them to live securely through integrated, intuitive solutions that protects their families and communities with the right security at the right moment.\\nAbout the Role:\\nDevelop Machine learning models to analyze and obtain practical insights from large volume of data that requires expertise at data exploration, analysis and feature engineering\\nExperiment and Develop POCs of innovative ideas to come up with new solutions for addressing security gaps\\nCreate machine learning pipelines to automate generation of efficient and better models\\nCommunicate and work with engineering teams to productionize the solutions\\nTaking ownership and responsibility of the solutions and driving to closure\\nParticipate in data and product analytics to develop customer insights and product features\\nImplement newer machine learning algorithms and models to improve the efficacy of the existing solutions\\nPublish research papers on the experiments and machine learning solutions\\nAbout you :\\n5+ years of experience in the field of Data Science\\n5+ years of programming experience in at least one of Python or Java\\n3+ years of working experience on large datasets using ML and experience with ML model life cycle\\nPhD degree in Computer Science, Data Science, Statistics, Mathematics or other related fields is preferred\\nDeep knowledge in Natural Language processing, Deep learning, statistics, predictive modeling and time series analysis.\\nPassionate about Cybersecurity and want to apply machine learning solutions in this space to solve security problems.\\nExperience working on Big data problems\\nExperience working on problems relevant to detecting risk, fraud and trust is an added advantage\\nExperience in working in AWS cloud environment is an added advantage\\nExperience with Publishing research papers\\n\\n\\nRoleResearch Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nComputer sciencePublishingdata scienceMachine learningPredictive modelingNatural language processingSensorsResearchAnalyticsPython', 'Job description\\nRoles and Responsibilities\\n\\nDetails in lined for Hiring Team to focus:\\nThe hiring is for a single Data Scientist (7-8+yrs) as he/she shall be an individual contributor.\\nWe shall seek for a strong java/python/scala with expertise into frameworks ML (spark/keras/tensorflow).\\nML concepts has to be thorough with proven expertise in ( Decision Trees, Random Forest, NLP) Deep Learning is excluded.\\nDesired Candidate Profile\\n\\n\\nPerks and Benefits\\n\\n\\nRoleTechnical Architect\\nIndustry TypeRecruitment / Staffing\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nKey Skills\\nTensorflowJavaNLPSCALAKerasSparkDecision TreesDeep LearningPythonRandom Forest', 'Job description\\nDear Candidates\\nWe are looking for a competent and enthusiastic candidate with the below requirement. This vital role ensures Cunesoft India Pvt Ltd (a Phlexglobal Company) Bangalore can provide a high-quality end product to internal and external users. This position requires strong technical and communication skills as well as both independent and team working, including working closely with all other areas of the software delivery team and the rest of the Technology department.\\nRoles and Responsibilities\\n\\nKey Activities\\nDevelop and improve the existing data mining and NLP related processes within our Regulatory Data Management platform\\nDevelop new ways of improving and transforming the regulatory processes of Phlexglobal customers.\\nInteract with product management, project management and development teams to develop additional modules and functions within the Phlexglobal Cloud Platform\\nDesign and create solutions for pre specified modules and functions\\nUse existing tools and techniques to develop and test new and existing work\\nDefine, create and execute automated test cases, i.e. unit tests\\nParticipate in troubleshooting and triaging of issues with different teams to drive towards root cause identification and resolution\\nSupport production deployment of applications and perform validation testing during the off-hours maintenance windows\\nSupport and fix existing and new identified issues by either customers or internal test teams.\\n\\nDesired Candidate Profile\\n\\n\\nRequired Skills & Experience\\n\\nMinimum 3+ years working experience in NLP, Artificial Intelligence, Machine Learning, Text Mining, Neural Networks\\nStrong programming skills using PYTHON\\nIn depth experience with OpenNLP, Stanford NLP or related NLP / data mining technologies\\nIn depth experience with Python and data libraries such as scikit learn, pandas, numpy, etc.\\nSelecting features, building and optimizing classifiers using Machine learning techniques\\nExcellent understanding of Machine Learning Techniques and Algorithms.\\nMust have Data mining / Natural Language Processing experience\\nMust have very good understanding of GIT\\nProcessing, Cleansing, and verifying the integrity of data\\nDevelop custom data models and algorithms to apply to data sets.\\nDefining validation strategies\\nDefining the preprocessing or feature engineering to be done on a given dataset\\nDefining data augmentation pipelines\\nTraining models and tuning their hyperparameters\\nAnalyzing the errors of the model and designing strategies to overcome them\\nDeploying models to production\\n\\nAdded advantages\\n3+ years experience using Microsoft .NET / C#\\nExposure to ML.Net, AutoML, NimbusML, etc\\nGood knowledge of Microsoft Visual Studio is preferred\\nGood to have Microsoft SQL Server, preferably Microsoft SQL Azure\\nPrevious experience in the Life sciences area\\n\\nOther requirements\\nExcellent verbal and written communication skills\\nMust be flexible, independent and self motivated\\nPunctual, Regular and consistent attendance\\nAs part of the Interview process, you should have attempted the below mentioned Kaggle project.\\n\\nhttps://www.kaggle.com/c/titanic\\n\\nWe would like to arrange a phone interview with you. Please confirm your interest in this position by sending your recent CV attached along with below details.\\n\\nTotal years of Experience :\\n\\nRelevant Experience :\\n\\nCurrent CTC :\\n\\nExpected CTC :\\n\\nNotice Period :\\n\\nCurrent Location :\\n\\nBest time to talk to you :\\n\\nCandidates with relevant experience can contact me.\\n\\nWe are looking for a candidate who can join us immediately / in less than 15-20 days / 30 days / ASAP\\n\\nPlease ignore, if you have already been interviewed within 3 months.\\n\\nThanks\\nSrini\\n\\nsarumugam@phlexglobal.com\\n+91 63660 85842\\n\\nDot Net Developer\\n\\nJunior (3-5 yrs), Mid (5-8 yrs) & Lead (8-12 yrs) level roles.\\n\\nCommercial experience in web development using the full Microsoft .Net development stack (specifically C#, MVC, .Net Core), SQL, front-end frameworks (jQuery, React, etc).\\n\\nCoding, Entity framework, Linq, Source control system (Any - TFS or GIT), Data structures\\n\\nSkilled in modern development principles (Agile, SOLID, TDD, design patterns, IoC)\\n\\nAt least theoretical knowledge - know-SQL database (example\\nAzure Cosmos)\\n\\nGood to have - Ideally experience of Azure, MVVM, microservices, message bus, containerisation, serverless.\\n\\nMicrosoft .Net development stack, C#, MVC, .Net Core, SQL, front-end frameworks, jQuery, React, Entity framework, Linq, TFS, GIT, Data structures, Agile, SOLID, TDD, design patterns, IoC, SQL database, Azure Cosmos, Azure, MVVM, microservices, message bus, containerisation, serverless\\nRoleSoftware Developer\\nIndustry TypePharmaceutical & Life Sciences\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Graduation Not Required\\nKey Skills\\npandaspythonnlpscikitlearndataminingneuralnetworkdeeplearningmachinelearningdatasciencenumpynaturallanguageprocessingartificialintelligence', \"Job description\\nAbout the role\\nWe are looking for skilled motivated professionals who will support and own multiple projects globally that drive business growth while still balancing compliance risk and partner friction. The role will cover areas such as (not limited to) Sanctions screening; Partner and user compliance; Customer due diligence; Transaction monitoring; Metrics development and monitoring; and Model and Strategy development - to help balance partner friction and compliance risk\\nWhat you'll do\\nDevelop and manage user risk rating models that meet applicable regulatory requirements and are aligned with standard methodologies and practices. Interpret large amounts of complex data to formulate problem statements, concise conclusions regarding underlying risk dynamics, trends, and opportunities Identify key risk indicators and metrics while developing and monitoring key parameters, enhance reporting, and identify new areas of analytic focus to better understand operational risk.\\nOwn compliance specific area - end to end - ranging from the discovery of the business problem to eventually working with the Engineering/Product teams to execute it Strategy design and analysis of domain-specific use-cases such as Reduction of cost of compliance;\\nImprove monitoring mechanism to alert any anomaly in compliance or business metric; Improve funnel for Partner onboarding, thereby improving user experience; and Drive multiple experiments to evaluate and quantify the hypothesis Extensive data analytics and SQL query writing Predictive modeling / Machine learning algorithms - using random Forest / Decision tree / Logistic regression\\nKey Qualifications\\n6 years of proven experience in a data-focused role such as product analytics, business analytics, business operations, or data science Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience Past experience in Payments or Compliance with a Product / Tech company serving millions of customers on multiple platforms and countries BA/BS in Mathematics, Statistics, Computer Science, Economics, Business or analytical field SQL mastery.\\nWrite efficient and complex code in SQL Experience in Python/R and in experimentation, A/B testing, and statistical modeling Define business metrics, including Key Performance Indicators, for financial products, in close partnership with Product Management and other leaders Proven ability to handle large datasets, explore and utilize raw data feeds\\nExcellent data visualization skills Love of data - you just go get the data you need and turn it into an insightful story. You know how to convert data into decisions without getting stuck in paralysis by analysis A well-organized, structured approach to problem-solving\\nStrong sense of ownership, accountability, and entrepreneurial spirit Able to lead change and solution-oriented Great communicator, problem-solver confident in decision making Independent autonomous, while still a strong teammate Enthusiastic, self-starting and thrives in changing, agile environment.\\nRoleBusiness Analyst\\nIndustry TypeInternet\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategorySystem Design/Implementation/ERP/CRM\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nProduct managementComputer scienceIT strategyBusiness analyticsAnalyticalMachine learningAgileMonitoringSQLPython\", '----', 'Job description\\nWork location: Bengaluru (Currently, Remote)\\nShift timing: 12PM to 9PM\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\nDevelop a use case roadmap for a problem area or capability for the business. Frame the business problem into a Data Science or modelling problem.\\nExtract data from multiple sources. Mine and analyze data from company databases to drive optimization and improvement of product.\\nWork as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with Client Support, Product Management and Engineering team to strategize and execute the development of data products.\\nProcessing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data.\\nData mining using state-of-the-art methods. Selecting features, building and optimizing classifiers using ML/AI techniques.\\nPresent technical solutions to internal and external stakeholders in a formal setting, effectively communicating key concepts and functionalities\\nEffectively manage client expectations via direct and frequent communication with high quality results\\nDevelop front end deliverable solutions for stakeholders utilizing BI tools such as Tableau, Cognos, Excel, or similar\\nWork on multiple assignments concurrently, while handling priorities and challenges and meeting timelines basis project plan and roadmap.\\nBuild self-service tools for error detection, diagnosis, and predictive metrics.\\nBuild project plans, maintain to-do list, organize work, follow coding ethics, and have an eye for detail\\n\\n\\nQualifications\\nBachelor s or Master s degree in a quantitative discipline (e.g., data science, statistics, economics, mathematics, computer science) or significant relevant coursework/experience\\n4+ years professional experience in the field of data science or business intelligence\\nDemonstrated proficiency in PYTHON/SCALA/SQL and BIG DATA technologies and the proven ability to program in big data/cloud technologies such as AWS SPARK; minimum 3 years of experience\\nExperienced with Machine Learning algorithms such as logistic regression, linear regression, lasso regression, k-means, random forest, XG boost, KNN, SVM and neural network; minimum 2 years of experience\\nAble to produce elaborate documents/narrative suggesting actionable insights and recommendations leveraging BI tools such as Tableau\\nExpertise with Microsoft Office products; including Excel, PowerPoint, Word\\nGreat communication skills. Excellent written and verbal communication skills for coordinating across teams.\\nSelf-driven and results oriented. Willing to stretch to meet tight timelines.\\nStrong team player with ability to collaborate effectively across geographies/ time zones\\nGood understanding of Digital Marketing, Campaign Measurement, Web Analytics\\nDesirable Qualifications:\\nProfessional experience working with R\\nProfessional experience working with Power BI, Cognos, Dash, Looker, Domo\\nProfessional experience in fraud analytics, customer journey, attribution modeling, churn modeling, predictive analytics, customer segmentation, feature creation, statistical testing, a/b testing, production curve modeling, NLP, and partner recommendations.\\nProfessional analytical consulting experience with clients in Retail, Finance, Travel, or Home and Business Services\\nRoleProduct Manager\\nIndustry TypeAdvertising & Marketing\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Computers\\nPG :Post Graduation Not Required\\nKey Skills\\nData ScienceBusiness IntelligenceLogistic RegressionData ScientistBig DataData MiningMachine LearningStatisticsPythonPredictive Analytics', 'Job description\\nBidgely is looking for extraordinary and dynamic Data Scientists to be part of its core team in Bangalore. You must have delivered advanced statistical and machine learning models as part of commercial products and created substantial intellectual property with business impact. You must enjoy working with large data and finding interesting patterns in the data through analytics experiments in a methodical and data driven scientific way. Be part of a highly energetic and innovative team that believes nothing is impossible with some creativity and hard work.\\nResponsibilities\\nResearch and develop advanced statistical and machine learning models for analysis of large-scale, high-dimensional data.\\nDig deeper into data, understand characteristics of data, evaluate alternate models and validate hypothesis through theoretical and empirical approaches.\\nProductize proven or working models into production quality code.\\nCollaborate with product management, marketing and engineering teams in Business Units to elicit understand their requirements challenges and develop potential solutions\\nStay current with latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.\\nFile patents for innovative solutions that add to company s IP portfolio\\nRequirements\\n4 to 6 years of strong experience in data mining, machine learning and statistical analysis.\\nBS/MS/PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes (only IITs / IISc / BITS / Top NITs or top US university should apply)\\nExperience in productizing models to code in a fast-paced start-up environment.\\nExpertise in Python programming language and fluency in analytical tools such as Matlab, R, Weka etc.\\nStrong intuition for data and Keen aptitude on large scale data analysis\\nStrong communication and collaboration skills.\\nRoleSoftware Developer\\nIndustry TypeAnalytics / KPO / Research\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nRProduct ManagementData ScientistComputer ScienceData AnalysisData MiningMachine LearningStatisticsStatistical AnalysisPython', 'Job description\\nRoles and Responsibilities:\\n\\nWork as part of a product team in defining, prototyping and implementing data science models/algorithms as part of the product.\\nBe able to research and apply the latest Machine Learning architecture solutions that work for big data Batches and Streams.\\nBuild data expertise, act like an owner for the company and manage complex data systems for a product or a group of products.\\nDesigning, integrating and documenting technical components for data flows or applications that perform analysis at a massive scale.\\nAlong with project managers, own the business outcomes/metrics which the data science model/algorithm drives.\\nBuild large scale data systems that would work across multiple geographies\\nSolid understanding of the mathematics of ML - Probability, Statistics, Linear Algebra of Matrices, Modelling Hyperparameter tuning for speed of learning & model performance.\\nAbility to understand business concerns and formulate them as technical problems that can be solved using Data/Math/Stats/ML.\\nExperience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.\\n\\n\\nDesired Candidate Profile:\\n\\n4+ Years of Relevant Experience.\\nHands on experience of coding in Python and SQL (MySQL and Postgres)\\nHands-on experience of applying and tuning the following algos of data science in multiple verticles:\\nRecommendation Algos (Collaborative filtering, Content filtering (ALS etc.))\\nClassification and Regression Algos\\nMachine Learning Algos (XGBoost, Random Forest)\\nClustering Algos (KMeans)\\nDimensionality Reduction Algos (PCA)\\nExperience of coding in Pyspark and Scala\\nWorking knowledge of Airflow, Hadoop (HDFS) and Git\\nTuning of various performance matrix (for accuracy, precision, recall, F1 Score, AUC, ROC)\\nExperience in Deep Learning Algos (Neural Network)\\n\\n\\nRoleTechnical Architect\\nIndustry TypeSoftware Product\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nAlgorithmsMySQLPython\\nData ScienceProbabilityBig DataKmeansMachine LearningStatisticsLinear Algebra\\nSkills highlighted with ‘‘ are preferred keyskills', 'Job description\\nGreetings from Onward Technologies!\\n\\nWe are Hiring for Data scientist for one of our prestigious Client.\\nPermanent Role.\\nJob description:\\nExp : 6 to 11years\\nLocation : Bangalore\\nNp : Max 15 to 30days\\n\\nPrimary Skill: Data science, Machine Learning,Structured Data Analysis\\nRoleProject Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nKey Skills\\ndata bricksPysparkData scienceMachine LearningStatisticsPython', 'Job description\\nRoles and Responsibilities\\nJob Description\\nWhat You Will Do :Job Description: Senior Data Scientist\\nOur Analytics Services group has an open, full-time position in the Bangalore region for a Senior data scientist.  The senior data scientist will be working with our clients on new product development/ new solution development as well as improve on current solutions.\\nFunctional Responsibilities\\n        Develop strong statistical approaches to solution development. Candidate should be well versed in executing statistical models  on Regression, Ancova, Factor analysis, Cluster analysis, Text based mining, and similar modeling approaches.\\n        Evaluate model effectiveness and ability to translate the statistical requirements into excel based examples.\\nCandidate should be proficient in writing good code in Python, PySpark.\\n        Strong proficiency with manipulating big data with R , Python, SQL. A high comfort level with data manipulation and extraction of meaningful insights from large data and prior experience of working with large data is a plus. Experience with SAS is acceptable\\nCandidate should have good working knowledge on AI and ML and should have applied these techniques on some of their recent projects\\n        Being creative in identifying new techniques and processes to streamline and increase efficiency and effectiveness of current work-streams is a plus.\\n        High level of attention to detail and problem solving \\nProfessional requirement\\nPost graduate degree in Economics, MBA, Statistics, Mathematics, Operations Research, Quantitative Analysis, or related field\\n6-10 years of consolidated work experience in Analytic Industry.\\nStrong statistical and quantitative analysis skills. Knowledge of Statistical Analysis techniques which are used in Marketing analytics.\\nAdvanced knowledge of SQL and experience with statistical packages such as Python, Spark, PySpark, R. Experience with Oracles Exadata environment is a plus.\\nExcellent data interpretation skills. Experience in using charting/reporting\\nSkilled in MS-Office, specifically Excel and Powerpoint\\nShould have basic knowledge of market research & any specific knowledge on Retail and FMCG/CPG/Pharma industry will be an added advantage.\\nKnowledge on Retailer loyalty card data/Store transaction level data will be an added advantage.\\n\\n\\nDesired Candidate Profile\\nMust have skill: statistical modeling, pyspark, python\\nNP : we can accept max 60 days. 90 days NP please avoid\\n\\n\\nRoleData science\\nIndustry TypeSoftware Product\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :Any Graduate\\nKey Skills\\nPysparkStatistical ModelingPython\\nRFactor AnalysisExcel PowerpointSASMarketing AnalyticsStatistical AnalysisSQLCluster Analysis\\nSkills highlighted with ‘‘ are preferred keyskills', 'Job description\\nRole : Sr Data Scientist / Tech Lead - Data Science\\n\\nResponsibilities -\\nLead a team of data scientists, machine learning engineers and big data specialists\\nBe the main point of contact for the customers\\nLead data mining and collection procedures\\nEnsure data quality and integrity\\nInterpret and analyze data problems\\nConceive, plan and prioritize data projects\\nBuild analytic systems and predictive models\\nTest performance of data-driven products\\nVisualize data and create reports\\nExperiment with new models and techniques\\nAlign data projects with organizational goals\\n\\nRequirements (please read carefully)\\nVery strong in statistics fundamentals. Not all data is Big Data. The candidate should be able to derive statistical insights from very few data points if required, using traditional statistical methods.\\nEducation - no bar, but preferably from a Statistics academic background (eg MSc-Stats, MSc-Econometrics etc), given the first point. Any Relevant Graduate (BE/B Tech, MCA Prefer)\\nStrong expertise in Python (any other statistical languages/tools like R, SAS, SPSS etc are just optional, but Python is absolutely essential). If the person is very strong in Python, but has almost nil knowledge in the other statistical tools, he/she will still be considered a good candidate for this role.\\nProven experience as a Data Scientist or similar role, for about 7-8 years\\nSolid understanding of machine learning and AI concepts, especially wrt choice of apt candidate algorithms for a use case, and model evaluation.\\nGood expertise in writing SQL queries (should not be dependent upon anyone else for pulling in data, joining them, data wrangling etc)\\nKnowledge of data management and visualization techniques -- more from a Data Science perspective.\\nShould be able to grasp business problems, ask the right questions to better understand the problem breadthwise /depthwise, design apt solutions, and explain that to the business stakeholders.\\n\\nWork Experience Required: 6-9 yrs.\\nRoleTeam Lead/Technical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization, Any Graduate\\nPG :MS/M.Sc(Science) in Statistics, MCA in Any Specialization\\nDoctorate :Doctorate Not Required\\nKey Skills\\nData ScienceRArtificial IntelligenceBig DataSQL QueriesData MiningMachine LearningStatisticsPythonSQL', 'Job description\\nKey Requirements:\\n• Data-oriented personality\\n• Good applied statistics skills, such as distributions, statistical testing, regression, etc.\\nExperience with Deep Learning, BERT, Transformer, LSTM, RNN, Text Classification, Clustering.\\n• At least 2 - 9 years of experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\\n\\n• Experience working with and creating data architectures, data management, data analysis and data extraction\\n\\n• Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\n\\n• Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\n\\n• Ability to grasp nuances of business quickly.\\n\\n• Ability to problem solve and break down the complex problem into solvable pieces.\\n\\n• Ability to deliver quick and accurate results for each analysis/task\\n\\n• Ability to do work within tight timelines\\n\\nThe ideal candidate should constantly stays on top of the industry’s trends, in order to provide forward-thinking recommendations to the business. In this capacity, the candidate will strive to build an in-depth understanding of the problem domain and available business data assets, especially those pertaining to strategic initiatives and value-based programs.\\n\\nThe idea candidate would identify the data the business should be collecting, devises methods of instrumenting the business’s system in order to extract this information and work with other data and analytics departments to develop the processes that transform raw data into actionable business insights and will also mentor supporting personnel for this position, continuously ensuring effective execution of duties at this junior level.\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Maths, Statistics, Computers, BCA in Computers, B.Tech/B.E. in Computers, B.A in Statistics, Maths\\nPG :Any Postgraduate\\nDoctorate :Doctorate Not Required\\nKey Skills\\nKerasLSTM BERT Quantitative Analyses PySparkDeep Learning Clustering PyTorch Computer Science RNN Text ClassificationPython SQL.TensorFlow', 'Job description\\nHiring for B2B saas product companies across Pan INDIA\\n\\nSkills And Experience :\\n\\n- Masters in a Computer Science, Artificial Intelligence, Machine Learning, or related technical field) or Ph.D. preferred\\n\\n- 7+ years of experience in data science roles\\n\\n- Experience in applied machine learning or artificial intelligence\\n\\n- Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.\\n\\n- Experience applying modern machine learning techniques\\n\\n- Experience with one or more general-purpose programming languages (Python, Java, or C/C++)\\n\\n- Experience advising a team on innovative methodologies, data science tools, and environments on machine learning and data modeling applications.\\n\\nRequirements:\\n\\n- Frameworks - TensorFlow, PyTorch, etc\\n\\n- Cloud platforms and Big Data domains is a plus (e.g. Hadoop, Spark, AWS, GCP, MS Azure)\\n\\n- working with Geospatial data is a plus\\nRoleAnalytics Manager\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nPG :MS/M.Sc(Science) in Computers, M.Tech in Computers, MCA in Computers\\nDoctorate :Ph.D/Doctorate in Any Specialization\\nKey Skills\\nData ScienceTensorflowAzureData ScientistPySparkHadoopData ModelingMachine LearningAWSPythonGeo Spatial', 'Job description\\nEngagement and collaboration with globally deployed, multi-disciplinary teams to design and implement efficient, well-focused, statistically fit-for-purpose studies, analyse, visualize and interpret data, build and validate models and simulations.\\nWork primarily with Biology teams to design experiments, carry out multi-omics data analysis. Should have sound working knowledge of cheminformatics, microbiomics and network biology.\\nBuild mathematical and statistical models biological and other related datasets. Application of ML/AI techniques, deep learning methods and network science to drive innovations in biology/non-biology dataset including image data.\\nBuild capabilities to be democratized and carry-out upskilling sessions to non-experts.\\nShould work in inter-disciplinary teams that will include product formulators, process/packaging engineers, clinicians, measurement scientists, bio-informaticians, claim experts, and other data scientists, both internal to the company and external partners.\\nDemonstrate agility by extending the analytics application beyond biology dataset.\\nCandidate must be able to communicate the analytical results and insights effectively with the program manager and senior management.\\nRoleBio-Technical Research Associate/Scientist\\nIndustry TypeRecruitment / Staffing\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\ndeep learningData analysisNetworkingmanagementAnalyticalPackagingBiologyAnalytics', 'Job description\\nDynamic recruiting professional with 7 - 10 years of high-performance tech recruiting experience with search firms and /or mid-large-sized technology companies.\\nExperience in engaging and hiring the best talent for Data Engineers, Data Scientist and SAP\\nOpen to learning from your peers managers, anything that helps you do your job better day in day out also often share best practices in hiring talent attraction strategies with them.\\nWork well with teams as also on your own as a high-impact individual contributor.\\nUse social media, job boards, Internet sourcing, and other technical means to source candidates for open jobs.\\nUnderstanding of modern recruiting methods like hackathons but are equally comfortable with old school methods as well.\\nWork with internal technology teams and hiring managers to assist with recruitment efforts across levels.\\nWork in sync with the company-wide recruitment strategy. This may include job posting optimization, recruiting marketing channel development, search selection using job boards, digital and non-digital employment marketing, comprehensive recruitment campaign planning, talent planning, stakeholder management, etc.\\nIdentify and source appropriate talent for current open roles within the organization using traditional non-traditional means of recruiting.\\nProactively develop talent pools/talent communities to dip into when hiring is in full swing.\\nManage the end-to-end recruitment process and life-cycle, including sourcing, initial assessments, telephonic personal interviews culminating in offers maintaining the appropriate MIS.\\nRoleRecruitment Executive\\nIndustry TypeIT Services & Consulting\\nFunctional AreaHR, Recruitment, Administration, IR\\nEmployment TypeFull Time, Permanent\\nRole CategoryHR/ Recruitment / IR\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nChannel DevelopmentSocial MediaCampaign PlanningSelectionHiringSourcingIndividual ContributorJob PostingRecruitment', 'Job description\\nWe are a team of applied scientists working on machine learning components in the whole sponsored search stack. Our team works on problems related to machine learning, deep learning, natural language processing, image understanding, optimization, information retrieval, auction theory, among others. Our work entails building large-scale machine learning systems for ad matching, filtration, ranking, and multiobjective optimization, and a number of other ML-driven business problems.\\nYou will design, implement, analyze, tune complex algorithms and ML systems and the supporting infrastructure for operating on large datasets. You will collaborate with top machine learning scientists and engineers in delivering direct business impact. Were looking for sound understanding and insight into productionizing machine learning models in large-scale systems, an ability to pick up new technical areas, as well as a commitment to developing, delivering, and supporting algorithms in production.\\nQualifications :\\nMS/BS in CS/EE, mathematical or machine learning related disciplines, with 3 or more years of experience\\nSolid understanding of probability, statistics, machine learning, data science\\nA/B testing analysis of ML models, and optimizing models for accuracy\\nExperience with Hadoop, Spark, or other distributed computing systems for large-scale training prediction with ML models.\\nEnd-to-end system design: data analysis, feature engineering, technique selection implementation, debugging, and maintenance in production.\\nExperience implementing machine learning algorithms or research papers from scratch.\\nRoleInstructional Designer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - System Programming\\nEmployment TypeFull Time, Permanent\\nRole CategoryQA/Testing/Documentation\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\ndeep learningData analysisdata scienceDebuggingMachine learningSystem designInformation retrievalNatural language processingResearchmicrosoft', 'Job description\\nKey Responsibilities:\\n\\n• Harvest Natural Language resources from the Web. You will also be responsible for rapid bootstrapping of domain-specific and multilingual Natural Language models and syntactic parsing and text classification\\n• Have large-scale development and deployment, performance monitoring, tuning and optimization of Natural Language models\\n• Interface using ontologies, discourse processing, language generation and summarization.\\n• Responsible for annotation of texts using Natural Language Processing annotators such as inception\\n• Transform a model from research to production and ability to fine-tune model performance in a production setting using adaptive/incremental machine learning techniques\\n\\nSkills Required:\\n• Masters (With 5 years of experience) or PhD degree (2 years of experience) in computer science, engineering, linguistics, or a related field.\\n• Experience in natural language processing technologies and services with emphasis in one or more of the following:\\n• Data acquisition and NL modeling: harvesting NL resources from the Web, rapid bootstrapping of domain-specific and multilingual NL models for named-entity, syntactic parsing and text classification\\n• NL systems: large-scale development and deployment, performance monitoring, tuning and optimization of NL models\\n• NL methodology: grammar-based, data-driven and machine learning-based, hybrid approaches\\n• NL technologies: spoken language understanding, language translation, natural language search, syntax-semantics.\\n• Interfaces using ontologies, discourse processing, language generation and summarization, interactive NL systems\\n• In depth understanding of language processing technology, a strong software background and experience with processing large scale multilingual texts through effective use of computing resources.\\n• Hands on experience with NLTK tool, tokenization, lemmatization, NER model architecture, creating an NLP pipeline with sentence resolver, relationship extraction, chunk merge approach\\n• Annotation of texts using NLP annotators such as inception\\n• Transforming a model from research to production and ability to fine-tune model performance in a production setting using adaptive/incremental machine learning techniques\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :MCA in Computers, M.Tech in Computers, MS/M.Sc(Science) in Computers\\nDoctorate :Ph.D/Doctorate in Computers, Linguistics\\nKey Skills\\nNLPSoftware EngineeringWeb TechnologiesNLTK ToolNatural Language ProcessingComputer ScienceData AcquisitionMachine Learning']\n"
     ]
    }
   ],
   "source": [
    "job_description = []\n",
    "\n",
    "for i in job_decrip:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_des = driver.find_element_by_xpath('//section[@class=\"job-desc\"]')\n",
    "        job_description.append(job_des.text)\n",
    "    except:\n",
    "        job_description.append('----')\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2edc4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(Jobs),len(Location),len(companies),len(job_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd627d2e",
   "metadata": {},
   "source": [
    "### Creating DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fa5c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Scientist_job = pd.DataFrame({})\n",
    "Data_Scientist_job['job-title'] = Jobs[:10]\n",
    "Data_Scientist_job['job-location'] = Location[:10]\n",
    "Data_Scientist_job['company_name'] = companies[:10]\n",
    "Data_Scientist_job['full job-description'] = job_description[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a080c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>full job-description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description\\n  Be a part of the Enterprise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SYMBIOSIS International W.L.L</td>\n",
       "      <td>Job description\\nRequired Candidate profile\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>Job description\\nData Scientist Primary Locati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Datamatics Global Services Ltd</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Job description\\nDear Candidates\\nWe are looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Job description\\nAbout the role\\nWe are lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>----</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Job description\\nWork location: Bengaluru (Cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bidgely Technologies Private Limited</td>\n",
       "      <td>Job description\\nBidgely is looking for extrao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title         job-location  \\\n",
       "0                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "1                 Data Scientist: Advanced Analytics  Bangalore/Bengaluru   \n",
       "2                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "3                                     DATA SCIENTIST  Bangalore/Bengaluru   \n",
       "4                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "5  Software Developer - Data Scientist / NLP / Ma...  Bangalore/Bengaluru   \n",
       "6                                     Data scientist  Bangalore/Bengaluru   \n",
       "7                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "8                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "9                              Senior Data Scientist  Bangalore/Bengaluru   \n",
       "\n",
       "                           company_name  \\\n",
       "0                 Philips India Limited   \n",
       "1                IBM India Pvt. Limited   \n",
       "2         SYMBIOSIS International W.L.L   \n",
       "3      McAfee Software (India) Pvt. Ltd   \n",
       "4        Datamatics Global Services Ltd   \n",
       "5        Cunesoft India Private Limited   \n",
       "6                                  Uber   \n",
       "7                IBM India Pvt. Limited   \n",
       "8                       Publicis Groupe   \n",
       "9  Bidgely Technologies Private Limited   \n",
       "\n",
       "                                full job-description  \n",
       "0  Job description\\n  Be a part of the Enterprise...  \n",
       "1                                               ----  \n",
       "2  Job description\\nRequired Candidate profile\\nW...  \n",
       "3  Job description\\nData Scientist Primary Locati...  \n",
       "4  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "5  Job description\\nDear Candidates\\nWe are looki...  \n",
       "6  Job description\\nAbout the role\\nWe are lookin...  \n",
       "7                                               ----  \n",
       "8  Job description\\nWork location: Bengaluru (Cur...  \n",
       "9  Job description\\nBidgely is looking for extrao...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127d6d0",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q3: In this question you have to scrape data using the filters available on the website.You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "375b90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e652a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inserting data scientist in search bar\n",
    "time.sleep(5)\n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f1844b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clicking on search button\n",
    "search_button = driver.find_element_by_class_name('btn')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66ba72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter = driver.find_element_by_xpath('//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]//i')\n",
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "25d8ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element_by_xpath('//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]//i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1638f0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist / Sr. Data Scientist',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Immediate Openings For DATA Scientist with 6 To 7 yrs of Experience',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - Noida',\n",
       " 'Data Scientist',\n",
       " 'Hiring Data Scientist Develope || IDS Infotech LTD || (Permanent WFH)',\n",
       " 'Hiring Data Scientist Develope || IDS Infotech LTD || (Permanent WFH)',\n",
       " 'Data Scientist - Machine Learning/NLP',\n",
       " 'Data Scientist - Machine Learning/NLP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist ( Machine Learning , Pyspark, Cloud , DevOps)',\n",
       " 'Data Scientist ( Machine Learning , Pyspark, Cloud , DevOps)',\n",
       " 'We are hiring- Data Scientist- Noida',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = [] ### storing job titles in list\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'): #scraping job title from website.\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70673d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CBRE South Asia Pvt Ltd',\n",
       " 'WEGARNER SOLUTIONS PRIVATE LIMITED',\n",
       " 'GABA Consultancy services',\n",
       " 'CARS24',\n",
       " 'Entune IT Consulting Private Limited',\n",
       " 'Decimal Technologies Pvt Ltd.',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'R Systems International Ltd.',\n",
       " 'IDS Infotech Ltd.',\n",
       " 'IDS Infotech Ltd.',\n",
       " 'TalPro',\n",
       " 'TalPro',\n",
       " 'Country Veggie',\n",
       " 'Ashkom Media India Private Limited',\n",
       " 'Fractal Analytics',\n",
       " 'inVentiv International Pharma Services Pvt. Ltd.',\n",
       " 'JUMBO CONSULTANTS',\n",
       " 'JUMBO CONSULTANTS',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'iNICU']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = [] ## storing company name in list\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'): #scraping company name from website\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a84895eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram',\n",
       " 'Noida, Pune, Mumbai (All Areas)',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida',\n",
       " 'Noida(Sector-59 Noida)',\n",
       " 'Chandigarh, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Chandigarh, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpur, Ghaziabad, Jaunpur, Kanpur, Delhi, Lucknow, Agra, Gurgaon, Rajkot, Bengaluru',\n",
       " 'Noida',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Remote',\n",
       " 'Remote',\n",
       " 'Delhi / NCR',\n",
       " 'Delhi']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc = [] ### Storing location data in list\n",
    "for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span[1]'): #scraping location data from webite\n",
    "    job_loc.append(i.text)\n",
    "job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b0367fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-4 Yrs',\n",
       " '0-5 Yrs',\n",
       " '0-0 Yrs',\n",
       " '1-5 Yrs',\n",
       " '5-8 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-6 Yrs',\n",
       " '2-4 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '4-9 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-5 Yrs']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_req = [] ### Storing required expirence in list.\n",
    "for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span'): ### scraping expirence required data from website.\n",
    "    exp_req.append(i.text)\n",
    "exp_req"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1467618",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6104e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Decimal Technologies Pvt Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring Data Scientist Develope || IDS Infotech...</td>\n",
       "      <td>Chandigarh, Hyderabad/Secunderabad, Chennai, B...</td>\n",
       "      <td>IDS Infotech Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring Data Scientist Develope || IDS Infotech...</td>\n",
       "      <td>Chandigarh, Hyderabad/Secunderabad, Chennai, B...</td>\n",
       "      <td>IDS Infotech Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0                                     Data Scientist   \n",
       "1                Data Scientist / Sr. Data Scientist   \n",
       "2  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "3                      Data Scientist / Data Analyst   \n",
       "4  Immediate Openings For DATA Scientist with 6 T...   \n",
       "5                                     Data Scientist   \n",
       "6                      Senior Data Scientist - Noida   \n",
       "7                                     Data Scientist   \n",
       "8  Hiring Data Scientist Develope || IDS Infotech...   \n",
       "9  Hiring Data Scientist Develope || IDS Infotech...   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1                    Noida, Pune, Mumbai (All Areas)   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6                                              Noida   \n",
       "7                             Noida(Sector-59 Noida)   \n",
       "8  Chandigarh, Hyderabad/Secunderabad, Chennai, B...   \n",
       "9  Chandigarh, Hyderabad/Secunderabad, Chennai, B...   \n",
       "\n",
       "                                     company_name experience_required  \n",
       "0                         CBRE South Asia Pvt Ltd             2-4 Yrs  \n",
       "1              WEGARNER SOLUTIONS PRIVATE LIMITED             0-5 Yrs  \n",
       "2                       GABA Consultancy services             0-0 Yrs  \n",
       "3                                          CARS24             1-5 Yrs  \n",
       "4            Entune IT Consulting Private Limited             5-8 Yrs  \n",
       "5                   Decimal Technologies Pvt Ltd.             1-3 Yrs  \n",
       "6  Optum Global Solutions (India) Private Limited             2-6 Yrs  \n",
       "7                    R Systems International Ltd.            5-10 Yrs  \n",
       "8                               IDS Infotech Ltd.            5-10 Yrs  \n",
       "9                               IDS Infotech Ltd.            5-10 Yrs  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['job-title'] = job_title[:10]\n",
    "df['job-location'] = job_loc[:10]\n",
    "df['company_name'] = company_name[:10]\n",
    "df['experience_required'] = exp_req[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87ce8d",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f9306c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/member/home/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4b74e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_src = driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/div[1]/div/div/input\")\n",
    "job_src.send_keys('Data scientist') ### inserting Data Scientist in Job title search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31e58980",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/div[3]/div/input')\n",
    "loc.send_keys('Noida') ### Inserting Noida in location search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7637db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_button = driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/button\")\n",
    "src_button.click() ### Clicking search button\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4fe9188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited',\n",
       " 'Pixel Vision',\n",
       " 'Biz2Credit Inc',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Newgen Software',\n",
       " 'Crowe',\n",
       " 'Techlive',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Ericsson',\n",
       " 'DataTrained',\n",
       " 'NEC Opportunities',\n",
       " 'Deciman',\n",
       " 'SearchUrCollege',\n",
       " 'Uncodemy',\n",
       " 'Emerging India Analytics',\n",
       " 'Conduent',\n",
       " 'Innovacer',\n",
       " 'Innovacer',\n",
       " 'WhizHack Technologies Pvt Ltd',\n",
       " 'British Council',\n",
       " 'WishFin',\n",
       " 'Airtel India',\n",
       " 'dunnhumby',\n",
       " 'Data Trained Education',\n",
       " 'Flip Robo Technologies',\n",
       " 'Decision Tree Analytics And Services',\n",
       " 'MasterCard',\n",
       " 'Ameriprise Financial',\n",
       " 'Algoscale',\n",
       " 'Decision Tree Analytics And Services']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "company_name = [] ## Scraping company name data.\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]//span'): \n",
    "    company_name.append(i.text)\n",
    "    \n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9093ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11d',\n",
       " '21d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '22d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '6d',\n",
       " '24h',\n",
       " '3d',\n",
       " '10d',\n",
       " '30d+',\n",
       " '2d',\n",
       " '2d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '4d',\n",
       " '26d',\n",
       " '24h',\n",
       " '30d+',\n",
       " '4d',\n",
       " '1d',\n",
       " '1d',\n",
       " '2d',\n",
       " '1d',\n",
       " '9d',\n",
       " '11d',\n",
       " '30d+',\n",
       " '1d']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_ago = [] ### Scraping Days_ago data from website.\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]'): \n",
    "    days_ago.append(i.text)\n",
    "days_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "30eeaec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '4.1',\n",
       " '',\n",
       " '3.3',\n",
       " '3.8',\n",
       " '5.0',\n",
       " '',\n",
       " '4.1',\n",
       " '4.6',\n",
       " '',\n",
       " '3.7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3.1',\n",
       " '3.8',\n",
       " '3.8',\n",
       " '',\n",
       " '3.7',\n",
       " '3.8',\n",
       " '3.8',\n",
       " '4.1',\n",
       " '',\n",
       " '4.3',\n",
       " '4.7',\n",
       " '4.2',\n",
       " '3.8',\n",
       " '3.9',\n",
       " '4.7']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []### Scraping Ratings for company\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"d-flex flex-column css-x75kgh e1rrn5ka3\"]'):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae0bd3",
   "metadata": {},
   "source": [
    "### Creating Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa07b861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>No. of days ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>11d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>21d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>22d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DataTrained</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company name No. of days ago Rating\n",
       "0  Liberin Technologies Private Limited             11d       \n",
       "1                          Pixel Vision             21d       \n",
       "2                        Biz2Credit Inc            30d+    4.1\n",
       "3          Salasar New Age Technologies            30d+       \n",
       "4                       Newgen Software             22d    3.3\n",
       "5                                 Crowe            30d+    3.8\n",
       "6                              Techlive            30d+    5.0\n",
       "7          Salasar New Age Technologies            30d+       \n",
       "8                              Ericsson              6d    4.1\n",
       "9                           DataTrained             24h    4.6"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Company name'] = company_name[:10]\n",
    "df['No. of days ago'] = days_ago[:10]\n",
    "df['Rating'] = rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd105e4",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. from https://www.glassdoor.co.in/Salaries/index.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8780828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6969090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search = driver.find_element_by_id('KeywordSearch')\n",
    "job_search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b5d5d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_search = driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[6]')\n",
    "loc_search.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe79487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_class_name('gd-btn-mkt')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef9b03c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'IBM',\n",
       " 'Accenture',\n",
       " 'Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'EXL Service',\n",
       " 'Optum',\n",
       " 'Optum Global Solutions',\n",
       " 'ZS Associates',\n",
       " 'Innovaccer',\n",
       " 'OYO',\n",
       " 'Nagarro',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'CARS24.com',\n",
       " 'dunnhumby',\n",
       " 'Vidooly Media Tech',\n",
       " 'Tech Mahindra',\n",
       " 'Fresher']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_name = [] ### Scarping company names.\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"css-f3vw95 e1aj7ssy3\"]'):\n",
    "    com_name.append(i.text)\n",
    "com_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d21950cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Average',\n",
       " '₹xx,xxx',\n",
       " '18 salaries',\n",
       " '18 salaries',\n",
       " '15 salaries',\n",
       " '15 salaries',\n",
       " '14 salaries',\n",
       " '14 salaries',\n",
       " '10 salaries',\n",
       " '9 salaries',\n",
       " '9 salaries',\n",
       " '9 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries',\n",
       " '7 salaries',\n",
       " '7 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries',\n",
       " '5 salaries',\n",
       " '5 salaries']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_of_salaries = [] ### Scraping number of salaries.\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"m-0 css-1b6bxoo\"]'):\n",
    "    No_of_salaries.append(i.text)\n",
    "No_of_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "487cb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "del No_of_salaries[0:2] ### Removing the first to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eb40454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,12,205',\n",
       " '₹9,00,000',\n",
       " '₹11,63,336',\n",
       " '₹xx,xx,xxx',\n",
       " '₹x,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹x,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xxx',\n",
       " '₹xx,xx,xxx',\n",
       " '₹xx,xxx']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_salary = [] ### Scraping average salary.\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]//h3'):\n",
    "    avg_salary.append(i.text)\n",
    "avg_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2782d829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Range: ₹3L - ₹13L',\n",
       " 'Range: ₹6L - ₹27L',\n",
       " 'Range: ₹6L - ₹22L',\n",
       " 'Range: ₹xL - ₹xCr',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xxL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xxT - ₹xxT',\n",
       " 'Range: ₹xL - ₹xxL',\n",
       " 'Range: ₹xxT - ₹xL']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_range = [] ### Scraping Minimum and maximum range of salary.\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"d-block d-lg-none m-0 css-1b6bxoo\"]'):\n",
    "    min_max_range.append(i.text)\n",
    "min_max_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "219b360f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9',\n",
       " '3.9',\n",
       " '4.1',\n",
       " '3.9',\n",
       " '4',\n",
       " '3.6',\n",
       " '4.2',\n",
       " '3.6',\n",
       " '3.7',\n",
       " '3.9',\n",
       " '4',\n",
       " '3.8',\n",
       " '3.3',\n",
       " '4',\n",
       " '3.8',\n",
       " '4.1',\n",
       " '4.1',\n",
       " '3.7',\n",
       " '3.6',\n",
       " '4.2']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = []\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"m-0 css-kyx745\"]'):\n",
    "    Rating.append(i.text)\n",
    "Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9052944",
   "metadata": {},
   "source": [
    "### Creating DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c76908da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Min salary and Max Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹6,12,205</td>\n",
       "      <td>Range: ₹3L - ₹13L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹9,00,000</td>\n",
       "      <td>Range: ₹6L - ₹27L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹11,63,336</td>\n",
       "      <td>Range: ₹6L - ₹22L</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xCr</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹x,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹x,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>Range: ₹xL - ₹xxL</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company name  Number of salaries Min salary and Max Salary  \\\n",
       "0  Tata Consultancy Services           ₹6,12,205         Range: ₹3L - ₹13L   \n",
       "1                        IBM           ₹9,00,000         Range: ₹6L - ₹27L   \n",
       "2                  Accenture          ₹11,63,336         Range: ₹6L - ₹22L   \n",
       "3                  Delhivery          ₹xx,xx,xxx         Range: ₹xL - ₹xCr   \n",
       "4         Ericsson-Worldwide           ₹x,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "5         UnitedHealth Group          ₹xx,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "6         Valiance Solutions           ₹x,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "7                EXL Service          ₹xx,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "8                      Optum          ₹xx,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "9     Optum Global Solutions          ₹xx,xx,xxx         Range: ₹xL - ₹xxL   \n",
       "\n",
       "  Rating  \n",
       "0    3.9  \n",
       "1    3.9  \n",
       "2    4.1  \n",
       "3    3.9  \n",
       "4      4  \n",
       "5    3.6  \n",
       "6    4.2  \n",
       "7    3.6  \n",
       "8    3.7  \n",
       "9    3.9  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Company name'] = com_name[:10]\n",
    "df[' Number of salaries'] = No_of_salaries[:10]\n",
    "df[' Number of salaries'] = avg_salary[:10]\n",
    "df['Min salary and Max Salary'] = min_max_range[:10]\n",
    "df['Rating'] = Rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059a972",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:1. Brand 2. Product Description 3. Price 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "713ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d2a6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "src.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d105e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_class_name('L0Z3Pu')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "daa5f9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=4',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=5',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=6',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=7',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=8',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=9',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=10',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav = []\n",
    "for i in driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a'):\n",
    "    nav.append(i.get_attribute('href'))\n",
    "nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "24e41711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ee145e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "brand = [] ### Empty list for brand name\n",
    "description = [] ### Empty list for product description\n",
    "price = [] ### Empty list for Price's\n",
    "off = [] ### Empty list for discounts\n",
    "count = 1 ### Counter to stop for loop at page 3\n",
    "for i in nav:\n",
    "    if count<=3:\n",
    "        driver.get(i)\n",
    "        for i in driver.find_element_by_xpath('//div[@class=\"_2WkVRV\"]'): ### Scraping brand name\n",
    "            brand.append(i.text)\n",
    "        for i in driver.find_element_by_xpath('//a[@class=\"IRpwTa\"]'): ### Scraping product description\n",
    "            description.append(i.text)\n",
    "        for i in driver.find_element_by_xpath('//div[@class=\"_30jeq3\"]'): ### Scraping product price\n",
    "            price.append(i.text)\n",
    "        for i in driver.find_element_by_xpath('//div[@class=\"_3Ay6Sb\"]'): ### Scraping discount on product.\n",
    "            off.append(i.text)\n",
    "    count+=1 ### Increasing counter value by one.\n",
    "print(len(brand),len(description),len(price),len(off))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6c3c264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "      <td>₹739</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>22% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>₹664</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹323</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection, Gradient, Night Vision Retro Sq...</td>\n",
       "      <td>₹305</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Gradient, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹426</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized Retro Square Sunglasses (54)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price  \\\n",
       "0            Wrogn                  Mirrored Wayfarer Sunglasses (51)  ₹739   \n",
       "1        ROYAL SON     Polarized, UV Protection Round Sunglasses (53)  ₹664   \n",
       "2        Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹599   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹699   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON  Polarized, UV Protection Rectangular Sunglasse...  ₹664   \n",
       "96          GANSTA              UV Protection Aviator Sunglasses (57)  ₹323   \n",
       "97           Fravy  UV Protection, Gradient, Night Vision Retro Sq...  ₹305   \n",
       "98  ROZZETTA CRAFT  Gradient, UV Protection Round Sunglasses (Free...  ₹426   \n",
       "99   VINCENT CHASE             Polarized Retro Square Sunglasses (54)  ₹799   \n",
       "\n",
       "   Discount  \n",
       "0   71% off  \n",
       "1   66% off  \n",
       "2   88% off  \n",
       "3   25% off  \n",
       "4   22% off  \n",
       "..      ...  \n",
       "95  55% off  \n",
       "96  83% off  \n",
       "97  84% off  \n",
       "98  78% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Brand'] = brand[:100]\n",
    "df['Description'] = description[:100]\n",
    "df['Price'] = price[:100]\n",
    "df['Discount'] = off[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddfce2",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0f8fe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8620c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "all_review = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a')\n",
    "link = all_review.get_attribute('href')\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e4490e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=1',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=3',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=4',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=5',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=6',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=7',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=8',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=9',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=10',\n",
       " 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages =[] \n",
    "for i in driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a'):\n",
    "    pages.append(i.get_attribute('href'))\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cfffd47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 110 110\n"
     ]
    }
   ],
   "source": [
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "count = 1\n",
    "for i in pages:\n",
    "    if count <=11:\n",
    "        driver.get(i)\n",
    "        for x in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "            Rating.append(x.text)\n",
    "        for r in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "            Review_summary.append(r.text)\n",
    "        for f in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):\n",
    "            Full_review.append(f.text.replace('\\n',''))\n",
    "    count+=1\n",
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a3cc4",
   "metadata": {},
   "source": [
    "### Creating Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6dc6c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performanceCamera is superbThe ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera 📸 And Display touching very N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Value for money product. This iphone 11 is rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review summary  \\\n",
       "0       5         Simply awesome   \n",
       "1       5              Brilliant   \n",
       "2       5       Perfect product!   \n",
       "3       5              Fabulous!   \n",
       "4       5      Worth every penny   \n",
       "..    ...                    ...   \n",
       "95      5              Fabulous!   \n",
       "96      5              Just wow!   \n",
       "97      5  Mind-blowing purchase   \n",
       "98      5              Excellent   \n",
       "99      5              Excellent   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Everything is perfect pictures come out so cle...  \n",
       "96  The ultimate performanceCamera is superbThe ba...  \n",
       "97  Excellent camera 📸 And Display touching very N...  \n",
       "98  A perfect phone and a good battery super camer...  \n",
       "99  Value for money product. This iphone 11 is rea...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Rating'] = Rating[:100]\n",
    "df['Review summary'] = Review_summary[:100]\n",
    "df['Full review'] = Full_review[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdbaf6",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "75e04fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.cm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c678469",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_bar.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6a9a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_btn = driver.find_element_by_class_name('L0Z3Pu')\n",
    "src_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1f51a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links =[]\n",
    "for i in driver.find_elements_by_class_name('_2UzuFa'):\n",
    "    links.append(i.get_attribute('href'))\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "189de282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clicking page 2.\n",
    "page_2 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[2]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "## Collecting all the products urls.\n",
    "page_2_links =[]\n",
    "for i in driver.find_elements_by_class_name('_3bPFwb'):\n",
    "    page_2_links.append(i.get_attribute('href'))\n",
    "len(page_2_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3b4160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clicking page 3.\n",
    "page_3 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "## Collecting each product url from page 3\n",
    "page_3_links = []\n",
    "for i in driver.find_elements_by_class_name('_2UzuFa'):\n",
    "    page_3_links.append(i.get_attribute('href'))\n",
    "len(page_3_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50dc0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_discription = []\n",
    "Price = []\n",
    "Discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aedec7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a97683c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "for i in links:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    ## Fetching Brand name\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_xpath('//span[@class=\"G6XhRU\"]')\n",
    "        Brand.append(brand_name.text)\n",
    "    except:\n",
    "        Brand.append('-')\n",
    "    ## Fetching Product discription\n",
    "    try:\n",
    "        prd_discp = driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')\n",
    "        Product_discription.append(prd_discp.text)\n",
    "    except:\n",
    "        Product_discription.append('-')\n",
    "    ## Fetching Price detail\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')\n",
    "    ## Fetching Discount on each product\n",
    "    try:\n",
    "        discount = find_element_by_xpath('//div[@class=\"_3Ay6Sb _31Dcoz pZkvcx\"]')\n",
    "        Discount.append(discount.text)\n",
    "    except:\n",
    "        Discount.append('-')\n",
    "        \n",
    "print(len(Brand),len(Product_discription),len(Price), len(Discount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "106340ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80 80\n"
     ]
    }
   ],
   "source": [
    "for i in page_2_links:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    ## Fetching Brand name\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_xpath('//span[@class=\"G6XhRU\"]')\n",
    "        Brand.append(brand_name.text)\n",
    "    except:\n",
    "        Brand.append('-')\n",
    "    ## Fetching Product discription\n",
    "    try:\n",
    "        prd_discp = driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')\n",
    "        Product_discription.append(prd_discp.text)\n",
    "    except:\n",
    "        Product_discription.append('-')\n",
    "    ## Fetching Price detail\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')\n",
    "    ## Fetching Discount on each product\n",
    "    try:\n",
    "        discount = find_element_by_xpath('//div[@class=\"_3Ay6Sb _31Dcoz pZkvcx\"]')\n",
    "        Discount.append(discount.text)\n",
    "    except:\n",
    "        Discount.append('-')\n",
    "        \n",
    "print(len(Brand),len(Product_discription),len(Price), len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93ba6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "for i in page_3_links[:20]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    ## Fetching Brand name\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_xpath('//span[@class=\"G6XhRU\"]')\n",
    "        Brand.append(brand_name.text)\n",
    "    except:\n",
    "        Brand.append('-')\n",
    "    ## Fetching Product discription\n",
    "    try:\n",
    "        prd_discp = driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')\n",
    "        Product_discription.append(prd_discp.text)\n",
    "    except:\n",
    "        Product_discription.append('-')\n",
    "    ## Fetching Price detail\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')\n",
    "    ## Fetching Discount on each product\n",
    "    try:\n",
    "        discount = find_element_by_xpath('//div[@class=\"_3Ay6Sb _31Dcoz pZkvcx\"]')\n",
    "        Discount.append(discount.text)\n",
    "    except:\n",
    "        Discount.append('-')\n",
    "        \n",
    "print(len(Brand),len(Product_discription),len(Price), len(Discount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca9666",
   "metadata": {},
   "source": [
    "### Creating DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "83ed693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹1,219</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Sneakers For Men  (Olive)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEHANOSA</td>\n",
       "      <td>Sneakers For Men  (Multicolor)</td>\n",
       "      <td>₹419</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Luxury Branded Fashionable Men's Casual Walkin...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men  (Tan)</td>\n",
       "      <td>₹899</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men  (Black)</td>\n",
       "      <td>₹407</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹360</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹1,299</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product Description   Price  \\\n",
       "0        DUCATI                           Sneakers For Men  (Black)  ₹1,219   \n",
       "1         Zorth                           Sneakers For Men  (Olive)    ₹499   \n",
       "2        Chevit   Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹599   \n",
       "3      PEHANOSA                      Sneakers For Men  (Multicolor)    ₹419   \n",
       "4      ASTEROID   Luxury Branded Fashionable Men's Casual Walkin...    ₹499   \n",
       "..           ...                                                ...     ...   \n",
       "95     RED TAPE                             Sneakers For Men  (Tan)    ₹899   \n",
       "96       BRUTON   Modern & Trendy Collection Combo Pack of 02 Sh...    ₹499   \n",
       "97      Numenzo                           Sneakers For Men  (Black)    ₹407   \n",
       "98       Chevit   Smart Casuals Canvas Shoes Combo pack of 2 Sne...    ₹360   \n",
       "99  bacca bucci                           Sneakers For Men  (White)  ₹1,299   \n",
       "\n",
       "   discount %  \n",
       "0           -  \n",
       "1           -  \n",
       "2           -  \n",
       "3           -  \n",
       "4           -  \n",
       "..        ...  \n",
       "95          -  \n",
       "96          -  \n",
       "97          -  \n",
       "98          -  \n",
       "99          -  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Brand'] = Brand\n",
    "df['Product Description'] = Product_discription\n",
    "df['Price'] = Price\n",
    "df['discount %'] = Discount\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f592715",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7efdf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fb11d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selecting price filter 5319.0 TO 10479.0 as  Rs. 6649 to Rs. 13099 is not showing on website.\n",
    "price_filter = driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e5d09955",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selecting color filter black.\n",
    "color_filter = driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "321d7b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [] # storing page 1 product urls\n",
    "for i in driver.find_elements_by_xpath('//a[@style=\"display: block;\"]'):\n",
    "    urls.append(i.get_attribute('href'))\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ce6a608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = [] ### For storing Brand Name \n",
    "Description = [] ### For storing Description\n",
    "Price = [] ### For storing Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0e6bee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_class_name('pdp-title')\n",
    "        Brand.append(brand_name.text)\n",
    "    except:\n",
    "        Brand.append('-')\n",
    "    try:\n",
    "        descrip = driver.find_element_by_class_name('pdp-name')\n",
    "        Description.append(descrip.text)\n",
    "    except:\n",
    "        Description.append('-')\n",
    "    try:\n",
    "        price = driver.find_element_by_class_name('pdp-price')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4e2cf7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "503b1a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e99dd9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7d24a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clicking on page 2\n",
    "page_2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[3]/a').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3e80a523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_2 = [] ### Storing secand page product urls.\n",
    "for i in driver.find_elements_by_xpath('//a[@style=\"display: block;\"]'):\n",
    "    urls_2.append(i.get_attribute('href'))\n",
    "len(urls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5477be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in urls_2:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand_name = driver.find_element_by_class_name('pdp-title')\n",
    "        Brand.append(brand_name.text)\n",
    "    except:\n",
    "        Brand.append('-')\n",
    "    try:\n",
    "        descrip = driver.find_element_by_class_name('pdp-name')\n",
    "        Description.append(descrip.text)\n",
    "    except:\n",
    "        Description.append('-')\n",
    "    try:\n",
    "        price = driver.find_element_by_class_name('pdp-price')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f590baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "06fda11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black Renew Retaliation TR 3 Gym Shoes</td>\n",
       "      <td>Rs. 5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Black Cell Fraction Fade Running Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black &amp; White Blazer Low '77 Vintage Leath...</td>\n",
       "      <td>Rs. 7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex Black Project Rock Recruit BSR Woven De...</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Black Crater Remixa Sneakers</td>\n",
       "      <td>Rs. 5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Black Riveted Leather Block Heels</td>\n",
       "      <td>Rs. 5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Black Leather Sneakers</td>\n",
       "      <td>Rs. 6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Black Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Black Woven Design Charged Rogue 2 Runni...</td>\n",
       "      <td>Rs. 5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Black Leather Driving Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description     Price\n",
       "0           Nike         Men Black Renew Retaliation TR 3 Gym Shoes  Rs. 5995\n",
       "1           Puma         Men Black Cell Fraction Fade Running Shoes  Rs. 6999\n",
       "2           Nike  Men Black & White Blazer Low '77 Vintage Leath...  Rs. 7195\n",
       "3   UNDER ARMOUR  Unisex Black Project Rock Recruit BSR Woven De...  Rs. 9999\n",
       "4           Nike                   Men Black Crater Remixa Sneakers  Rs. 5495\n",
       "..           ...                                                ...       ...\n",
       "95          Geox                  Black Riveted Leather Block Heels  Rs. 5624\n",
       "96          Geox                       Women Black Leather Sneakers  Rs. 6749\n",
       "97  Kenneth Cole              Men Black Solid Leather Formal Derbys  Rs. 6293\n",
       "98  UNDER ARMOUR  Women Black Woven Design Charged Rogue 2 Runni...  Rs. 5599\n",
       "99          Geox                    Men Black Leather Driving Shoes  Rs. 9999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Creating DataFrame\n",
    "df = pd.DataFrame({})\n",
    "df['Brand'] = Brand\n",
    "df['Description'] = Description\n",
    "df['Price'] = Price\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20ba37",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "### Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”  After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "#### 1. title\n",
    "#### 2. Ratings\n",
    "#### 3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2720418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "82c5b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_bar = driver.find_element_by_id('twotabsearchtextbox')\n",
    "Search_bar.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "600c61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_id('nav-search-submit-text')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fda3b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selecting filter button Intel i7\n",
    "Filter = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-navigation-item\"]/span')\n",
    "for i in Filter:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f1d1c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selecting filter button Intel i9\n",
    "Filter = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-navigation-item\"]/span')\n",
    "for i in Filter:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "11b80fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_link = [] ### Storing product links\n",
    "for i in driver.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]/a'):\n",
    "    product_link.append(i.get_attribute('href'))\n",
    "len(product_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a3d4f821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "97264e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = [] ## for storing product titles\n",
    "Rating = [] ## For storing Rating of product \n",
    "Price = [] ## For storing price of product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e1241e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "for i in product_link[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        title = driver.find_element_by_id('productTitle')\n",
    "        Title.append(title.text)\n",
    "    except:\n",
    "        Title.append('-')\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//span[@id=\"priceblock_ourprice\"]')\n",
    "        Price.append(price.text)\n",
    "    except:\n",
    "        Price.append('-')\n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]')\n",
    "        Rating.append(rating.text)\n",
    "    except:\n",
    "        Rating.append('-')\n",
    "print(len(Title),len(Rating),len(Price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a0e62",
   "metadata": {},
   "source": [
    "### Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "54408570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>₹1,07,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹1,09,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>₹81,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹71,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>₹1,07,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹1,09,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Predator Helios 300 Core i7 10th Generati...</td>\n",
       "      <td>3 out of 5</td>\n",
       "      <td>₹1,37,500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion 5 10th Gen Intel Core i7-10750H ...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹82,990.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating  \\\n",
       "0  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  4.5 out of 5   \n",
       "1  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5   \n",
       "2  MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....  3.6 out of 5   \n",
       "3  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.3 out of 5   \n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5   \n",
       "5  ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...  4.2 out of 5   \n",
       "6  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  4.5 out of 5   \n",
       "7  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5   \n",
       "8  Acer Predator Helios 300 Core i7 10th Generati...    3 out of 5   \n",
       "9  Lenovo Legion 5 10th Gen Intel Core i7-10750H ...  4.4 out of 5   \n",
       "\n",
       "          Price  \n",
       "0  ₹1,07,990.00  \n",
       "1  ₹1,09,990.00  \n",
       "2    ₹81,990.00  \n",
       "3    ₹84,990.00  \n",
       "4             -  \n",
       "5    ₹71,990.00  \n",
       "6  ₹1,07,990.00  \n",
       "7  ₹1,09,990.00  \n",
       "8  ₹1,37,500.00  \n",
       "9    ₹82,990.00  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df['Title'] = Title\n",
    "df['Rating'] = Rating\n",
    "df['Price'] = Price\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3e46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
